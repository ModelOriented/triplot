<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Description of aspect importance method • triplot</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- dalexverse --><link href="../dalexverse.css" rel="stylesheet">
<link href="../dalexverse-2.css" rel="stylesheet">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Description of aspect importance method">
<meta property="og:description" content="triplot">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a class="navbar-brand" href="../index.html">triplot</a>
        <div class="info">
          <span class="partof">part of the <a href="https://github.com/ModelOriented/DrWhy">DrWhy.AI</a>
           developed by the <a href="https://mi2.mini.pw.edu.pl/">MI^2 DataLab</a> </span>
          <span class="version version-default">0.1.0</span>
        </div>
      </div>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/vignette_aspect_importance.html">Aspect importance function examples</a>
    </li>
    <li>
      <a href="../articles/vignette_aspect_importance_description.html">Description of aspect importance method</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
        <li>
  <a href="https://github.com/kasiapekala/triplot/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Description of aspect importance method</h1>
                        <h4 class="author">Katarzyna Pękala</h4>
            
            <h4 class="date">2020-04-20</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/kasiapekala/triplot/blob/master/vignettes/vignette_aspect_importance_description.Rmd"><code>vignettes/vignette_aspect_importance_description.Rmd</code></a></small>
      <div class="hidden name"><code>vignette_aspect_importance_description.Rmd</code></div>

    </div>

    
    
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<p>Aspect importance takes on the challenge of interpreting model built on highly dimensional data. There exist a number of methods for local explanation of black-box models, like Break Down, Shap or LIME. However, the problem arises when the explanatory variables are correlated.</p>
<p>Aspect importance’s aim is to increase the interpretability of the black box model by providing instance-level explainer for the groups of explanatory variables. It enables grouping predictors into entities called aspects. Afterwards, it can calculate the contribution of those aspects to the prediction.</p>
</div>
<div id="intuition" class="section level1">
<h1 class="hasAnchor">
<a href="#intuition" class="anchor"></a>Intuition</h1>
<p>Let’s suppose that we built a model on highly dimensional data and we are using this model to predict an outcome for a new observation. We would like to gain insight which features are contributing more and which less, to this calculated prediction. However, when we calculate such importance of every single feature, the image may be still unclear, because there is so many of them. To gain better understanding, we can group those features. And afterwards, we can calculate the contribution (importance) to the prediction of every group of features (aspects). Hence the method aspect importance.</p>
<p>To achieve that goal, the method works in following way: it uses subset of observations from the original dataset and than it modifies it, so every observation will have at least one aspect (meaning at least one group of features) replaced by the data from the observation of interest. Then we will build linear model that will predict how those replacements change the prediction of the modified data.</p>
</div>
<div id="method" class="section level1">
<h1 class="hasAnchor">
<a href="#method" class="anchor"></a>Method</h1>
<p>We start by having dataset <span class="math inline">\(\mathcal{X}\)</span> and model <span class="math inline">\(f\)</span> built on this dataset. We would like to explain the prediction for the observation of interest <span class="math inline">\(x_*\)</span>.</p>
<p>Before we can use the method, we need to group the explanatory variables into aspects. We can use two different approaches: we can built the aspect list arbitrarily by using domain expertise or we can use <code><a href="../reference/group_variables.html">group_variables()</a></code> function that will do the grouping for us by using variables correlations. In the second approach, we are going to get aspects where every absolute value of pair-wise correlation of explanatory variables is no smaller than a given level. It should be noted that <code><a href="../reference/group_variables.html">group_variables()</a></code> works only for numerical variables.</p>
<p>The aspect importance function algorithm starts with sampling observations from the dataset <span class="math inline">\(\mathcal{X}\)</span> into matrix <span class="math inline">\(A\)</span>.</p>
<p>Afterwards, it creates binary matrix <span class="math inline">\(X'\)</span>. The number of rows of this matrix is equal to number of sampled observations in <span class="math inline">\(A\)</span>. The number of columns is equal to the number of aspects.</p>
<p>In the next step, matrix <span class="math inline">\(A\)</span> is modified into matrix <span class="math inline">\(A'\)</span>. The binary matrix <span class="math inline">\(X'\)</span> directs how the modification will work: for given observation from <span class="math inline">\(A\)</span>, function checks in binary matrix <span class="math inline">\(X'\)</span> which aspects should be replaced by aspects from the observation of interest <span class="math inline">\(x_*\)</span>.</p>
<p>In result, we obtain a modified matrix <span class="math inline">\(A'\)</span> where for every observation at least one aspect is replaced with the data from the observation of interest.</p>
<p>Next, the method checks how the aspects replacement changed the prediction. In other words, it looks at the difference between predictions for modified matrix <span class="math inline">\(A'\)</span> and matrix <span class="math inline">\(A\)</span>.</p>
<p>Finally, we use linear model on the binary matrix <span class="math inline">\(X'\)</span> where the difference in predictions is the dependent variable. Model’s coefficients are the results we are looking for - the values of aspects importance.</p>
<p>We can interpret coefficient <span class="math inline">\(\beta_i\)</span> as the average change in prediction caused by replacing in <span class="math inline">\(A\)</span> the variables (grouped in aspect <span class="math inline">\(i\)</span>) by the variables from <span class="math inline">\(x_*\)</span>.</p>
<p>Aspect importance algorithm:</p>
<ul>
<li>
<span class="math inline">\(f\)</span> - model<br>
</li>
<li>
<span class="math inline">\(\mathcal{X}\)</span> - dataset<br>
</li>
<li>
<span class="math inline">\(x_*\)</span> - observation to be explained<br>
</li>
<li>
<span class="math inline">\(\mathcal{P}\)</span> - aspects list, <span class="math inline">\(\mathcal{P} = {q_1, ..., q_m}\)</span>, partition of set of indexes <span class="math inline">\(J = {1, ..., p}\)</span><br>
</li>
<li>
<span class="math inline">\(b\)</span> - size of sample</li>
</ul>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(A\)</span> = <span class="math inline">\([a_i^j]_{b \times p}\)</span> = select_sample(<span class="math inline">\(\mathcal{X}\)</span>, <span class="math inline">\(b\)</span>)<br>
sample (with replacement) B rows from <span class="math inline">\(\mathcal{X}\)</span></p></li>
<li><p><span class="math inline">\(X'\)</span> = <span class="math inline">\([{x'}_i^k]_{b \times m}\)</span> = sample_aspects(<span class="math inline">\(m\)</span>, <span class="math inline">\(b\)</span>)<br>
sample binary matrix of size <span class="math inline">\(b \times m\)</span></p></li>
<li><p><span class="math inline">\(A'\)</span> = <span class="math inline">\([{a'} _i^j]_{b\times p}\)</span> = replace_aspects(<span class="math inline">\(A\)</span>, <span class="math inline">\(X'\)</span>)<br><span class="math inline">\([{a'}_i^j] = [a_i^j]\)</span>, if <span class="math inline">\([{x'}_i^k] = 0\)</span> where <span class="math inline">\(j \in q_k\)</span><br><span class="math inline">\([{a'}_i^j] = x_{*j}\)</span>, if <span class="math inline">\([{x'}_i^k] = 1\)</span> where <span class="math inline">\(j \in q_k\)</span></p></li>
<li><p><span class="math inline">\(Y_m = f(A') - f(A)\)</span></p></li>
<li><p>fit linear model <span class="math inline">\(g\)</span>, <span class="math inline">\(g(X') = Y_m\)</span></p></li>
</ol>
<p>return coefficients of <span class="math inline">\(g\)</span></p>
</div>
<div id="example" class="section level1">
<h1 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h1>
<p>To illustrate how the method works, we will use <code>Boston Housing</code> dataset from <code>mlbench</code> package. This well known dataset contains housing data for 506 census tracts of Boston. We will be predicting <strong>cmedv</strong> - corrected median value of owner-occupied homes (in USD 1000’s).</p>
<p>We are going to build two models: linear regression model and random forest. Those models will be built only on numerical variables. Then we will check the predictions for the observation called <code>new_observation</code>.</p>
<div class="sourceCode" id="cb1"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">triplot</span>)
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">mlbench</span>)
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">randomForest</span>)
<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">123</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(<span class="st">"BostonHousing2"</span>)
<span class="no">Boston</span> <span class="kw">&lt;-</span> <span class="no">BostonHousing2</span>[,-<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">1</span>:<span class="fl">5</span>, <span class="fl">10</span>)]
<span class="no">Boston_no_target</span> <span class="kw">&lt;-</span> <span class="no">BostonHousing2</span>[,-<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">1</span>:<span class="fl">6</span>, <span class="fl">10</span>)]
<span class="no">new_observation</span> <span class="kw">&lt;-</span> <span class="no">Boston_no_target</span>[<span class="fl">4</span>,]
<span class="no">Boston_lm</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span>(<span class="no">cmedv</span> ~<span class="no">.</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">Boston</span>)
<span class="no">Boston_rf</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/randomForest/man/randomForest.html">randomForest</a></span>(<span class="no">cmedv</span> ~ <span class="no">.</span>, <span class="kw">data</span> <span class="kw">=</span> <span class="no">Boston</span>)
<span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">Boston_lm</span>, <span class="no">new_observation</span>)</pre></body></html></div>
<pre><code>#&gt;        4 
#&gt; 28.78676</code></pre>
<div class="sourceCode" id="cb3"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">Boston_rf</span>, <span class="no">new_observation</span>)</pre></body></html></div>
<pre><code>#&gt;       4 
#&gt; 34.4931</code></pre>
<p>As we observe that those two models’ predictions for the <code>new_observation</code> are different, we would like to understand which groups of the observation’s features contribute to this differences. For that, we will use <code>aspects_importance()</code>.</p>
<p>In the beginning, we have to build an aspect list. Then we will call <code>aspects_importance()</code> for both of those models to check:</p>
<ul>
<li>which aspects have the biggest contribution to the prediction in each case,</li>
<li>what is minimal value of pairwise absolute correlation in each group,</li>
<li>whether any aspect contains negatively correlated pair of features (<code>neg</code>).</li>
</ul>
<p>Finally, we will plot <code>aspects_importance()</code> results for both models.</p>
<p>We can notice that in random forest model, almost every group of features (except single feature <code>b</code>) have positive influence on the prediction. <code>Wealth</code> (<code>rm</code> and <code>lstat</code>) has the most important contribution, it’s significantly bigger than the rest. On the other hand, in linear model we can observe that some features have negative impact (<code>geo</code>, <code>structure</code>, <code>ptartio</code>). Nonetheless, positive contribution of <code>wealth</code> is still the most important, as in random forest model. After seeing this results, we can now understand why the prediction in linear model case is smaller than in random forest one.</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r"><span class="no">Boston_aspects_m</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="kw">geo</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"dis"</span>, <span class="st">"nox"</span>, <span class="st">"rad"</span>),
                         <span class="kw">wealth</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"rm"</span>, <span class="st">"lstat"</span>),
                         <span class="kw">structure</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"indus"</span>, <span class="st">"age"</span>, <span class="st">"zn"</span>),
                         <span class="kw">ptratio</span> <span class="kw">=</span> <span class="st">"ptratio"</span>,
                         <span class="kw">b</span> <span class="kw">=</span> <span class="st">"b"</span>,
                         <span class="kw">tax</span> <span class="kw">=</span> <span class="st">"tax"</span>,
                         <span class="kw">crim</span> <span class="kw">=</span> <span class="st">"crim"</span>)
<span class="no">Boston_ai_lm</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/aspect_importance.html">aspect_importance</a></span>(<span class="no">Boston_lm</span>, <span class="no">Boston_no_target</span>,
                           <span class="kw">predict_function</span> <span class="kw">=</span> <span class="no">predict</span>, <span class="no">new_observation</span>,
                           <span class="no">Boston_aspects_m</span>, <span class="kw">N</span> <span class="kw">=</span> <span class="fl">5000</span>, <span class="kw">show_cor</span> <span class="kw">=</span> <span class="fl">TRUE</span>,
                           <span class="kw">label</span> <span class="kw">=</span> <span class="st">"LM"</span>)
<span class="no">Boston_ai_rf</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/aspect_importance.html">aspect_importance</a></span>(<span class="no">Boston_rf</span>, <span class="no">Boston_no_target</span>,
                           <span class="kw">predict_function</span> <span class="kw">=</span> <span class="no">predict</span>, <span class="no">new_observation</span>,
                           <span class="no">Boston_aspects_m</span>, <span class="kw">N</span> <span class="kw">=</span> <span class="fl">5000</span>, <span class="kw">show_cor</span> <span class="kw">=</span> <span class="fl">TRUE</span>,
                           <span class="kw">label</span> <span class="kw">=</span> <span class="st">"RF"</span>)
<span class="no">Boston_ai_lm</span></pre></body></html></div>
<pre><code>#&gt;     aspects importance       features   min_cor sign
#&gt; 3    wealth     7.9568      rm, lstat 0.6408316  neg
#&gt; 2       geo    -3.9621  dis, nox, rad 0.4958065  neg
#&gt; 7       tax     2.5038            tax        NA     
#&gt; 4 structure    -1.0941 indus, age, zn 0.5444226  neg
#&gt; 5   ptratio    -0.3219        ptratio        NA     
#&gt; 6         b     0.2729              b        NA     
#&gt; 8      crim     0.2235           crim        NA</code></pre>
<div class="sourceCode" id="cb7"><html><body><pre class="r"><span class="no">Boston_ai_rf</span></pre></body></html></div>
<pre><code>#&gt;     aspects importance       features   min_cor sign
#&gt; 3    wealth   11.60018      rm, lstat 0.6408316  neg
#&gt; 4 structure    1.02818 indus, age, zn 0.5444226  neg
#&gt; 7       tax    0.90006            tax        NA     
#&gt; 2       geo    0.35672  dis, nox, rad 0.4958065  neg
#&gt; 5   ptratio    0.17091        ptratio        NA     
#&gt; 8      crim    0.08803           crim        NA     
#&gt; 6         b   -0.06641              b        NA</code></pre>
<div class="sourceCode" id="cb9"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(<span class="no">Boston_ai_lm</span>, <span class="no">Boston_ai_rf</span>, <span class="kw">add_importance</span> <span class="kw">=</span> <span class="fl">TRUE</span>)</pre></body></html></div>
<p><img src="vignette_aspect_importance_description_files/figure-html/aspect%20importance%20with%20manual%20aspects-1.png" width="700"></p>
<p>In some cases, manually grouping features into aspects may present some challenges. For that reason, we added function that can do that for us. Function <code><a href="../reference/group_variables.html">group_variables()</a></code> groups correlated features into aspects, given a correlation cut-off level.</p>
<p>Below we will use <code><a href="../reference/group_variables.html">group_variables()</a></code> function with a cut off level set on 0.6. As a result, we get a list of variables groups where absolute value of features’ pairwise correlation is at least at 0.6. Afterwards, we call <code>aspects_importance()</code> function again.</p>
<p>Since <code><a href="../reference/group_variables.html">group_variables()</a></code> built different list that us, we can observe a little bit different results. However, the final image still allow us to see that what we established as geographical and structure features, in general, have negative contribution on the prediction in linear case, while positive in the random forest one.</p>
<div class="sourceCode" id="cb10"><html><body><pre class="r"><span class="no">Boston_aspects_a</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/group_variables.html">group_variables</a></span>(<span class="no">Boston_no_target</span>, <span class="fl">0.6</span>)

<span class="no">Boston_ai_lm_2</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/aspect_importance.html">aspect_importance</a></span>(<span class="no">Boston_lm</span>, <span class="no">Boston_no_target</span>,
                           <span class="kw">predict_function</span> <span class="kw">=</span> <span class="no">predict</span>, <span class="no">new_observation</span>,
                           <span class="no">Boston_aspects_a</span>, <span class="kw">N</span> <span class="kw">=</span> <span class="fl">10000</span>, <span class="kw">show_cor</span> <span class="kw">=</span> <span class="fl">TRUE</span>,
                           <span class="kw">label</span> <span class="kw">=</span> <span class="st">"LM"</span>)
<span class="no">Boston_ai_rf_2</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/aspect_importance.html">aspect_importance</a></span>(<span class="no">Boston_rf</span>, <span class="no">Boston_no_target</span>,
                           <span class="kw">predict_function</span> <span class="kw">=</span> <span class="no">predict</span>, <span class="no">new_observation</span>,
                           <span class="no">Boston_aspects_a</span>, <span class="kw">N</span> <span class="kw">=</span> <span class="fl">10000</span>, <span class="kw">show_cor</span> <span class="kw">=</span> <span class="fl">TRUE</span>,
                           <span class="kw">label</span> <span class="kw">=</span> <span class="st">"RF"</span>)
<span class="no">Boston_ai_lm_2</span></pre></body></html></div>
<pre><code>#&gt;         aspects importance                   features   min_cor sign
#&gt; 4 aspect.group3     7.9860                  rm, lstat 0.6408316  neg
#&gt; 2 aspect.group1    -1.7999 crim, indus, nox, age, dis 0.6794867  neg
#&gt; 3 aspect.group2    -0.6908                         zn        NA     
#&gt; 5 aspect.group4     0.6281                   rad, tax 0.7048757  pos
#&gt; 7 aspect.group6     0.4711                          b        NA     
#&gt; 6 aspect.group5    -0.1835                    ptratio        NA</code></pre>
<div class="sourceCode" id="cb12"><html><body><pre class="r"><span class="no">Boston_ai_rf_2</span></pre></body></html></div>
<pre><code>#&gt;         aspects importance                   features   min_cor sign
#&gt; 4 aspect.group3   11.60548                  rm, lstat 0.6408316  neg
#&gt; 2 aspect.group1    1.11142 crim, indus, nox, age, dis 0.6794867  neg
#&gt; 5 aspect.group4    1.02974                   rad, tax 0.7048757  pos
#&gt; 6 aspect.group5    0.24018                    ptratio        NA     
#&gt; 7 aspect.group6    0.22562                          b        NA     
#&gt; 3 aspect.group2   -0.06245                         zn        NA</code></pre>
<div class="sourceCode" id="cb14"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(<span class="no">Boston_ai_lm_2</span>, <span class="no">Boston_ai_rf_2</span>, <span class="kw">aspects_on_axis</span> <span class="kw">=</span> <span class="fl">FALSE</span>, <span class="kw">add_importance</span> <span class="kw">=</span> <span class="fl">TRUE</span>)</pre></body></html></div>
<p><img src="vignette_aspect_importance_description_files/figure-html/aspect%20importance%20with%20automated%20aspects-1.png" width="700"></p>
</div>
<div id="hierarchical-aspects-importance" class="section level1">
<h1 class="hasAnchor">
<a href="#hierarchical-aspects-importance" class="anchor"></a>Hierarchical aspects importance</h1>
<p><code>Triplot</code> is a tool built on <code>aspects_importance</code> function, that allows us to go one step further in our understanding of the inner workings of a black box model.</p>
<p>It illustrates, in one place:</p>
<ul>
<li>the importance of every single feature,</li>
<li>hierarchical aspects importance (explained below),</li>
<li>order of grouping features into aspects in <code><a href="../reference/group_variables.html">group_variables()</a></code>.</li>
</ul>
<p>Hierarchical aspects importance allows us to check the values of aspects importance for the different levels of variables grouping. Method starts with looking at the aspect importance where every aspect has one, single variable. Afterwards, it iteratively creates bigger aspects by merging the ones with the highest level of absolute correlation into one aspect and calculating it’s contribution to the prediction.</p>
<p>It should be noted that similarly to <code><a href="../reference/group_variables.html">group_variables()</a></code>, <code><a href="../reference/triplot.html">triplot()</a></code> works for the datasets with only numerical variables.</p>
<div class="sourceCode" id="cb15"><html><body><pre class="r"><span class="fu"><a href="../reference/triplot.html">triplot</a></span>(<span class="no">Boston_lm</span>, <span class="no">Boston_no_target</span>, <span class="kw">predict_function</span> <span class="kw">=</span> <span class="no">predict</span>,
        <span class="no">new_observation</span>, <span class="kw">N</span> <span class="kw">=</span> <span class="fl">10000</span>, <span class="kw">add_importance_labels</span> <span class="kw">=</span> <span class="fl">TRUE</span>,
        <span class="kw">axis_lab_size</span> <span class="kw">=</span> <span class="fl">8</span>, <span class="kw">text_size</span> <span class="kw">=</span> <span class="fl">3</span>)</pre></body></html></div>
<p><img src="vignette_aspect_importance_description_files/figure-html/triplot-1.png" width="700"></p>
<div class="sourceCode" id="cb16"><html><body><pre class="r"><span class="fu"><a href="../reference/triplot.html">triplot</a></span>(<span class="no">Boston_rf</span>, <span class="no">Boston_no_target</span>, <span class="kw">predict_function</span> <span class="kw">=</span> <span class="no">predict</span>,
        <span class="no">new_observation</span>, <span class="kw">N</span> <span class="kw">=</span> <span class="fl">10000</span>, <span class="kw">add_importance_labels</span> <span class="kw">=</span> <span class="fl">TRUE</span>,
        <span class="kw">axis_lab_size</span> <span class="kw">=</span> <span class="fl">8</span>, <span class="kw">text_size</span> <span class="kw">=</span> <span class="fl">3</span>)</pre></body></html></div>
<p><img src="vignette_aspect_importance_description_files/figure-html/triplot-2.png" width="700"></p>
</div>
<div id="lasso" class="section level1">
<h1 class="hasAnchor">
<a href="#lasso" class="anchor"></a>Lasso</h1>
<p>Behind the scenes, aspect importance numbers are really linear model coefficients. That allowed us to add one more tool to control the method result. By using lasso regression, we can control how many nonzero coefficients (nonzero aspects importance values) are present in the final explanation. To use <code><a href="../reference/aspect_importance.html">aspect_importance()</a></code> with lasso, we have to provide <code>n_var</code> parameter, which declares how many aspects importance values we would like to get in <code><a href="../reference/aspect_importance.html">aspect_importance()</a></code> results.</p>
<p>Suppose that in our last example (random forest model with aspect list build by <code>group_variables</code>), we would like to calculate the importance of variables’ aspects, while controlling that three of them should be equal to 0. We will call <code><a href="../reference/aspect_importance.html">aspect_importance()</a></code> on this model, with <code>n_var</code> parameter set to 3.</p>
<p>In result, we get what we expected - three nonzero aspect importance values. We can observe that there exists significant difference between the level of contribution of aspect containing <code>rm</code> and <code>lstat</code> features and the other two groups.</p>
<div class="sourceCode" id="cb17"><html><body><pre class="r"><span class="fu"><a href="../reference/aspect_importance.html">aspect_importance</a></span>(<span class="no">Boston_rf</span>, <span class="no">Boston_no_target</span>, <span class="kw">predict_function</span> <span class="kw">=</span> <span class="no">predict</span>,
                  <span class="no">new_observation</span>, <span class="no">Boston_aspects_a</span>, <span class="kw">N</span> <span class="kw">=</span> <span class="fl">10000</span>, <span class="kw">show_cor</span> <span class="kw">=</span> <span class="fl">TRUE</span>,
                  <span class="kw">n_var</span> <span class="kw">=</span> <span class="fl">3</span>)</pre></body></html></div>
<pre><code>#&gt;         aspects importance                   features   min_cor sign
#&gt; 4 aspect.group3   10.55857                  rm, lstat 0.6408316  neg
#&gt; 3 aspect.group2   -0.12409                         zn        NA     
#&gt; 2 aspect.group1    0.08732 crim, indus, nox, age, dis 0.6794867  neg
#&gt; 5 aspect.group4    0.00000                   rad, tax 0.7048757  pos
#&gt; 6 aspect.group5    0.00000                    ptratio        NA     
#&gt; 7 aspect.group6    0.00000                          b        NA</code></pre>
</div>
<div id="summary" class="section level1">
<h1 class="hasAnchor">
<a href="#summary" class="anchor"></a>Summary</h1>
<p>Aspect importance allow us to check how the level of prediction is influenced by the different groups of features. We added additional tools to this method that let us group features automatically, control how many nonzero values are in the method results or see how aspect importance values are changing while aspects are one by one increasing in size (hierarchical aspects importance).</p>
<p>However, we still see place for experimenting with stability of the results (size of the subset used by the <code>aspect_importance</code>), clarity of triplot and with lasso regression as the method extensions.</p>
</div>
<div id="session-info" class="section level1">
<h1 class="hasAnchor">
<a href="#session-info" class="anchor"></a>Session info</h1>
<div class="sourceCode" id="cb19"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html">sessionInfo</a></span>()</pre></body></html></div>
<pre><code>#&gt; R version 3.6.3 (2020-02-29)
#&gt; Platform: x86_64-w64-mingw32/x64 (64-bit)
#&gt; Running under: Windows 10 x64 (build 18362)
#&gt; 
#&gt; Matrix products: default
#&gt; 
#&gt; locale:
#&gt; [1] LC_COLLATE=Polish_Poland.1250  LC_CTYPE=Polish_Poland.1250   
#&gt; [3] LC_MONETARY=Polish_Poland.1250 LC_NUMERIC=C                  
#&gt; [5] LC_TIME=Polish_Poland.1250    
#&gt; 
#&gt; attached base packages:
#&gt; [1] stats     graphics  grDevices utils     datasets  methods   base     
#&gt; 
#&gt; other attached packages:
#&gt; [1] randomForest_4.6-14 mlbench_2.1-1       triplot_0.1.0      
#&gt; 
#&gt; loaded via a namespace (and not attached):
#&gt;  [1] Rcpp_1.0.4.6     compiler_3.6.3   pillar_1.4.3     ingredients_1.1 
#&gt;  [5] iterators_1.0.12 tools_3.6.3      digest_0.6.25    lattice_0.20-38 
#&gt;  [9] evaluate_0.14    memoise_1.1.0    lifecycle_0.2.0  tibble_3.0.0    
#&gt; [13] gtable_0.3.0     pkgconfig_2.0.3  rlang_0.4.5      foreach_1.5.0   
#&gt; [17] Matrix_1.2-18    cli_2.0.2        rstudioapi_0.11  yaml_2.2.1      
#&gt; [21] pkgdown_1.5.1    xfun_0.13        ggdendro_0.1-20  gridExtra_2.3   
#&gt; [25] stringr_1.4.0    dplyr_0.8.5      knitr_1.28       desc_1.2.0      
#&gt; [29] fs_1.4.1         vctrs_0.2.4      glmnet_3.0-2     tidyselect_1.0.0
#&gt; [33] rprojroot_1.3-2  grid_3.6.3       glue_1.4.0       R6_2.4.1        
#&gt; [37] DALEX_1.0.1      fansi_0.4.1      rmarkdown_2.1    farver_2.0.3    
#&gt; [41] purrr_0.3.3      ggplot2_3.3.0    magrittr_1.5     codetools_0.2-16
#&gt; [45] backports_1.1.6  scales_1.1.0     htmltools_0.4.0  ellipsis_0.3.0  
#&gt; [49] MASS_7.3-51.5    assertthat_0.2.1 shape_1.4.4      colorspace_1.4-1
#&gt; [53] labeling_0.3     stringi_1.4.6    munsell_0.5.0    crayon_1.3.4</code></pre>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Katarzyna Pekala, Przemyslaw Biecek.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
