---
output: github_document
---

```{r setup, include=FALSE, message=FALSE, warning=TRUE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE,
  fig.width = 12, 
  fig.height = 8, 
  fig.align = 'center', 
  fig.path = "man/figures/")

```

# triplot 

<!-- badges: start -->
[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/triplot)](https://cran.r-project.org/package=triplot)
[![R build status](https://github.com/ModelOriented/triplot/workflows/R-CMD-check/badge.svg)](https://github.com/ModelOriented/triplot/actions?query=workflow%3AR-CMD-check)
[![Codecov test coverage](https://codecov.io/gh/ModelOriented/triplot/branch/master/graph/badge.svg)](https://codecov.io/gh/ModelOriented/triplot?branch=master)
<!-- badges: end -->


## Overview


The `triplot` package provides tools for exploration of machine learning 
predictive models. It contains an instance-level explainer called `predict_aspects` (AKA `aspects_importance`), that is able to explain the contribution of the whole 
groups of explanatory variables. Furthermore, package delivers functionality called `triplot` - it illustrates how the importance of aspects (group of predictors) change depending on the size 
of aspects.

Key functions: 

* `predict_aspects()` for calculating the feature groups importance (called aspects importance) for a selected observation, 
* `predict_triplot()` and `model_triplot()` for summary of automatic aspect importance grouping, 
* `group_variables()` for grouping numeric features into aspects.

The `triplot` package is a part of [DrWhy.AI](http://DrWhy.AI) universe. More information about analysis of machine learning models can be found in
the [Explanatory Model Analysis. Explore, Explain and Examine Predictive Models](https://pbiecek.github.io/ema/) e-book.

## Installation

```{r eval = FALSE}
devtools::install_github("ModelOriented/triplot")
```


## Basic example

```{r include=FALSE}
library("triplot")
library("DALEX")

titanic <- titanic_imputed

model_titanic_glm <-
  glm(survived == 1 ~ .,
      titanic,
      family = "binomial")

aspects_titanic <-
  list(
    wealth = c("class", "fare"),
    family = c("sibsp", "parch"),
    personal = c("age", "gender"),
    embarked = "embarked"
  )

```

For the `titanic` dataset we build logistic regression model that predicts passenger survival. Afterwards, we group features into thematical aspects. We are interested in explaining the model prediction for the `chosen_passenger`.

```{r }
chosen_passenger <- titanic[2,]

chosen_passenger

predict(model_titanic_glm, chosen_passenger, type = "response")
```

It turns out that the model prediction for this passenger's survival is very low. 

Let's see which aspects have the biggest influence on it.

We start by building `DALEX` explainer and use it to call `predict_aspects()` function. Afterwards, we print and plot function results. 

We can observe that `wealth` variables have the biggest contribution to the prediction. This contribution is of a negative type. `Family` variables have positive influence on the prediction, but it is much smaller. `Embarked` has similar contribution as `family`, but of negative type. `Personal` aspects have very small contribution to the prediction.  

```{r}
explain_titanic <- explain(model_titanic_glm, 
                           data = titanic[, -8],
                           y = titanic$survived == "yes",
                           predict_function = predict,
                           label = "Logistic Regression",
                           verbose = FALSE)

ai_titanic <- predict_aspects(x = explain_titanic, 
                              new_observation = chosen_passenger[,-8],
                              variable_groups = aspects_titanic)

print(ai_titanic, show_features = TRUE)

plot(ai_titanic)
```

## Triplot

`Triplot` is a tool that allows us to go one step further in our understanding of the inner workings of a black box model. 

We can use it to investigate the **instance level** importance of features (using `predict_aspects` function) or to illustrate the **model level** importance of features (using `model_parts` function from `DALEX` package).

`Triplot` shows, in one place: 

* the importance of every single feature,
* hierarchical aspects importance, 
* order of grouping features into aspects in `group_variables()`.

`Triplot` can be only used on numerical features. 

To showcase `triplot`, we will choose numeric features from `apartments` dataset, build `DALEX` explainer, `model_triplot()` to calculate `triplot` object and then plot it.


```{r}

apartments_num <- apartments[,unlist(lapply(apartments, is.numeric))]

model_apartments <- lm(m2.price ~ ., data = apartments_num)

explain_apartments <- explain(model = model_apartments, 
                              data = apartments_num[, -1],
                              y = apartments_num[, 1],
                              verbose = FALSE)
set.seed(123)
```

We can observe that, at the model level, `surface` and `floor` have the biggest contribution. `Number of rooms` and `surface` are strongly correlated and together have strong influence on the prediction. 

```{r, fig.width=10}
tri_apartments <- model_triplot(explain_apartments)

plot(tri_apartments)
```

Afterwards, we are building triplot for single instance and it's prediction.

We can observe that for the given apartment `surface` has also big, positive influence on prediction. Adding `number of rooms` and then `construction year` to `surface's` aspect, increases its contribution.

We can see notice that `floor` has the small influence on the prediction of this observation, unlike in the model wise analysis.

```{r}
new_observation_apartments <- apartments_num[6,-1]

tri_apartments <- predict_triplot(explain_apartments, 
                                  new_observation = new_observation_apartments)

plot(tri_apartments)
```


## Acknowledgments

Work on this package was financially supported by the 
